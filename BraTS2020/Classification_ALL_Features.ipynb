{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":15124,"status":"ok","timestamp":1697766076658,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"wGr_uOfH5OHm","outputId":"407d30d5-dced-4fb0-f1c8-3bfb70d4c100"},"outputs":[],"source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","path = \"/content/drive/MyDrive/BraTS20-Invariant-feature\"\n","os.chdir(path)\n","os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xSvm6paw6GHt"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, accuracy_score, mean_absolute_error\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.model_selection import KFold, cross_val_score\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"TPa5rMPA6Pjp"},"source":["# Original 75 Features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3141,"status":"ok","timestamp":1697766196073,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"3PerpUWl6OIR","outputId":"5a544f3e-a009-4f4a-c68b-c4f3bd4c27a5"},"outputs":[],"source":["df_Original = pd.read_excel(\"original_radiomic_features_BraTS2020_addclass.xlsx\", sheet_name=0)\n","df_Original = df_Original.drop('Unnamed: 0', axis=1)\n","print(df_Original.shape)\n","print(df_Original.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1697766224944,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"BTssVZw3wG44","outputId":"4722e5f1-6897-4c28-d6f2-d237ad4b99dd"},"outputs":[],"source":["# Original dataset. Malignant high-grade glioma (HGG)\n","# ['LGG - Malignant low-grade glioma', 0]\n","# ['HGG - Malignant high-grade glioma', 1]\n","mapping = {'HGG': 1, 'LGG': 0}\n","df_Original['n_class'] = df_Original['n_class'].replace(mapping)\n","X = df_Original.iloc[:, :-1]\n","y = df_Original.iloc[:, -1:]\n","print(type(y))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1697766261936,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"71pd-gYGwTF8","outputId":"3111ec81-65ef-4193-f292-baed870b55e5"},"outputs":[],"source":["# Apply SMOTE to balance the dataset\n","from imblearn.over_sampling import SMOTE\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","\n","X_resampled, y_resampled = smote.fit_resample(X, y)\n","X_resampled.shape, y_resampled.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":124,"status":"ok","timestamp":1697766274591,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"-RGZIN7R7wrv","outputId":"14e41e87-dcc9-4046-e2ca-f44fc02529e0"},"outputs":[],"source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1697766276124,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"Q7Ym2p7a8Mpm","outputId":"016fa9cb-2227-4032-b92e-4e925e0df80f"},"outputs":[],"source":["count1 = y_test.iloc[:, 0].value_counts()[0]\n","count2 = y_test.iloc[:, 0].value_counts()[1]\n","print(count1)\n","print(count2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Irrvrsi8QWw"},"outputs":[],"source":["\"\"\"\n","  ada-boosting - stratified sampling\n","\"\"\"\n","\n","max_depth_range = np.arange(1, 20)\n","\n","train_accuracies_ada = []\n","test_accuracies_ada = []\n","train_losses_ada = []\n","test_losses_ada = []\n","\n","n_folds = 5\n","kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n","\n","for max_depth in max_depth_range:\n","    train_accuracy = []\n","    test_accuracy = []\n","    train_loss = []\n","    test_loss = []\n","\n","    for train_index, val_index in kf.split(X_train):\n","        X_train1, X_val1 = X_train.iloc[train_index], X_train.iloc[val_index]\n","        y_train1, y_val1 = y_train.iloc[train_index], y_train.iloc[val_index]\n","\n","        estimator = DecisionTreeRegressor(max_depth=max_depth, min_samples_split=5, criterion='squared_error', random_state=42)\n","        ada_boost = AdaBoostRegressor(estimator=estimator, n_estimators=100, learning_rate=0.002, loss='square', random_state=42)\n","        model = MultiOutputRegressor(ada_boost)\n","        model.fit(X_train1, y_train1)\n","\n","        train_accuracy.append(accuracy_score(y_train1.iloc[:, 0], (model.predict(X_train1)[:, 0] > 0.5).astype(int)))\n","        test_accuracy.append(accuracy_score(y_test.iloc[:, 0], (model.predict(X_test)[:, 0] > 0.5).astype(int)))\n","        train_loss.append(mean_absolute_error(y_train1, model.predict(X_train1)))\n","        test_loss.append(mean_absolute_error(y_test, model.predict(X_test)))\n","\n","    train_accuracies_ada.append(np.mean(train_accuracy))\n","    test_accuracies_ada.append(np.mean(test_accuracy))\n","    train_losses_ada.append(np.mean(train_loss))\n","    test_losses_ada.append(np.mean(test_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":971},"executionInfo":{"elapsed":873,"status":"ok","timestamp":1697766426451,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"uDLi3ShGijne","outputId":"dba43bf9-d94c-48a7-ec55-f88b0ac08a29"},"outputs":[],"source":["plt.plot(max_depth_range, train_accuracies_ada, label='training')\n","plt.plot(max_depth_range, test_accuracies_ada, label='testing')\n","\n","plt.xticks(np.arange(min(max_depth_range), max(max_depth_range)+1, 1, dtype=int))\n","\n","plt.xlabel('Depth', fontsize=20, fontweight='bold')\n","plt.ylabel('Accuracy', fontsize=20, fontweight='bold')\n","plt.legend()\n","plt.title('AdaBoost', fontsize=20, fontweight='bold')\n","plt.show()\n","\n","plt.plot(max_depth_range, train_losses_ada, label='training')\n","plt.plot(max_depth_range, test_losses_ada, label='testing')\n","\n","plt.xticks(np.arange(min(max_depth_range), max(max_depth_range)+1, 1, dtype=int))\n","\n","plt.xlabel('Depth', fontsize=20, fontweight='bold')\n","plt.ylabel('Loss', fontsize=20, fontweight='bold')\n","plt.legend()\n","plt.title('AdaBoost', fontsize=20, fontweight='bold')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_JJ9_Nh-ube"},"outputs":[],"source":["optimal_depth = 11\n","\n","train_accuracy_optimal = []\n","test_accuracy_optimal = []\n","train_loss_optimal = []\n","test_loss_optimal = []\n","\n","for train_index, val_index in kf.split(X_train):\n","    X_train1_optimal, X_val1_optimal = X_train.iloc[train_index], X_train.iloc[val_index]\n","    y_train1_optimal, y_val1_optimal = y_train.iloc[train_index], y_train.iloc[val_index]\n","\n","    estimator = DecisionTreeRegressor(max_depth=optimal_depth, min_samples_split=5, criterion='squared_error', random_state=42)\n","    ada_boost = AdaBoostRegressor(estimator=estimator, n_estimators=100, learning_rate=0.002, loss='square', random_state=42)\n","    model_optimal = MultiOutputRegressor(ada_boost)\n","    model_optimal.fit(X_train1_optimal, y_train1_optimal)\n","\n","    train_predictions_optimal = (model_optimal.predict(X_train1_optimal)[:, 0] > 0.5).astype(int)\n","    test_predictions_optimal = (model_optimal.predict(X_test)[:, 0] > 0.5).astype(int)\n","\n","    train_accuracy_optimal.append(accuracy_score(y_train1_optimal.iloc[:, 0], train_predictions_optimal))\n","    test_accuracy_optimal.append(accuracy_score(y_test.iloc[:, 0], test_predictions_optimal))\n","    train_loss_optimal.append(mean_absolute_error(y_train1_optimal, model.predict(X_train1_optimal)))\n","    test_loss_optimal.append(mean_absolute_error(y_test, model.predict(X_test)))\n","\n","train_accuracy_final = np.mean(train_accuracy_optimal)\n","test_accuracy_final = np.mean(test_accuracy_optimal)\n","train_loss_final = np.mean(train_loss)\n","test_loss_final = np.mean(test_loss)\n","\n","# Compute sensitivity and specificity\n","tn, fp, fn, tp = confusion_matrix(y_test.iloc[:, 0], test_predictions_optimal).ravel()\n","sensitivity_optimal = tp / (tp + fn)\n","specificity_optimal = tn / (tn + fp)\n","\n","# Compute AUC score\n","auc_score_optimal = roc_auc_score(y_test.iloc[:, 0], model_optimal.predict(X_test)[:, 0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1697766518452,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"sUt4WRrHxL3u","outputId":"57cb3db3-c636-49e9-e281-6e0164c644e5"},"outputs":[],"source":["print(\"Accuracy: {:.2f}\".format(test_accuracy_final))\n","print(\"Sensitivity: {:.2f}\".format(sensitivity_optimal))\n","print(\"Specificity: {:.2f}\".format(specificity_optimal))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5045,"status":"ok","timestamp":1697766556732,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"pHCGfXWwxVq9","outputId":"84d54216-1985-4b0b-e37e-f4e967137faf"},"outputs":[],"source":["# Number of bootstrap samples\n","n_bootstrap_samples = 1000\n","\n","sensitivity_values = []\n","specificity_values = []\n","auc_values = []\n","accuracy_values = []\n","\n","for _ in range(n_bootstrap_samples):\n","    # Resample the test dataset with replacement\n","    resampled_indices = np.random.choice(len(y_test), len(y_test), replace=True)\n","    y_test_resampled = y_test.iloc[resampled_indices]\n","    test_predictions_resampled = test_predictions_optimal[resampled_indices]\n","\n","    # Calculate accuracy, sensitivity and specificity for the resampled dataset\n","    tn, fp, fn, tp = confusion_matrix(y_test_resampled.iloc[:, 0], test_predictions_resampled).ravel()\n","    sensitivity = tp / (tp + fn)\n","    specificity = tn / (tn + fp)\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","\n","    # Calculate AUC for the resampled dataset\n","    auc = roc_auc_score(y_test_resampled.iloc[:, 0], test_predictions_resampled)\n","\n","    # Store the sensitivity, specificity, and AUC values\n","    sensitivity_values.append(sensitivity)\n","    specificity_values.append(specificity)\n","    accuracy_values.append(accuracy)\n","    auc_values.append(auc)\n","\n","# Calculate 95% confidence intervals (percentiles) for accuracy, sensitivity, specificity, and AUC\n","sensitivity_ci = np.percentile(sensitivity_values, [2.5, 97.5])\n","specificity_ci = np.percentile(specificity_values, [2.5, 97.5])\n","accuracy_ci = np.percentile(accuracy_values, [2.5, 97.5])\n","auc_ci = np.percentile(auc_values, [2.5, 97.5])\n","\n","print(\"Accuracy 95% CI:\", accuracy_ci)\n","print(\"Sensitivity 95% CI:\", sensitivity_ci)\n","print(\"Specificity 95% CI:\", specificity_ci)\n","print(\"AUC 95% CI:\", auc_ci)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1697766627461,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"Ka8-69BxGe-1","outputId":"5e572671-3477-4be3-a718-bfac3760676e"},"outputs":[],"source":["# Predictor Gain Calculation\n","feature_importances = np.zeros(X_train1_optimal.shape[1])\n","\n","# Iterate over all the decision trees in the AdaBoost ensemble\n","for tree in model_optimal.estimators_:\n","    decision_tree_model = tree.estimator\n","    decision_tree_model.fit(X_train1_optimal, y_train1_optimal)\n","    tree_importances = decision_tree_model.feature_importances_\n","    feature_importances += tree_importances\n","\n","# Normalize the importances to sum up to 100%\n","importance_percentage = (feature_importances / feature_importances.sum()) * 100\n","\n","# Modify the predictor names to remove \"original_\" part\n","predictor_names = [col.replace('original_', '') for col in df_Original.columns[:-1]]\n","\n","# Create a DataFrame to store the feature importances and their names\n","importance_df = pd.DataFrame({\n","    'Predictor': predictor_names,\n","    'Importance (%)': importance_percentage\n","})\n","\n","# Sort the DataFrame based on importance in descending order\n","importance_df = importance_df.sort_values(by='Importance (%)', ascending=False)\n","\n","# Reset the index of the DataFrame for a cleaner representation\n","importance_df.reset_index(drop=True, inplace=True)\n","\n","print(importance_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1343,"status":"ok","timestamp":1697766632271,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"mb6RsdhRKYGN","outputId":"194e6bbb-605d-46b4-b5aa-fdd9cda328e5"},"outputs":[],"source":["# Plot the feature importances as a horizontal bar plot\n","colors = ['red' if i < 6 else 'blue' for i in range(importance_df.shape[0])]\n","\n","plt.figure(figsize=(8, 13))\n","plt.barh(importance_df['Predictor'], importance_df['Importance (%)'],  color=colors)\n","plt.xlabel('Gain', fontsize=20, fontweight='bold')\n","plt.ylabel('Radiomics Metric', fontsize=20, fontweight='bold')\n","#plt.title('Feature Importances')\n","plt.gca().invert_yaxis()  \n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2526,"status":"ok","timestamp":1697766647369,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"E9gpTkIGRC4w","outputId":"75937c99-12cb-42be-9920-59c64c3a97cb"},"outputs":[],"source":["from scipy import stats\n","\n","# Get the top six predictors\n","top_six_predictors = 'original_' + importance_df.iloc[:6]['Predictor']\n","\n","# Plot box plots for each of the top six predictors based on the target variable\n","plt.figure(figsize=(16, 10))\n","for i, predictor in enumerate(top_six_predictors):\n","    plt.subplot(2, 3, i + 1)\n","    sns.boxplot(x=df_Original[df_Original.columns[-1]].map({0: 'Not HG/PDAC', 1: 'HGD/PDAC'}), y=df_Original[predictor], order=['HGD/PDAC', 'Not HGD/PDAC'])\n","    plt.xticks(fontsize=15)\n","    plt.xlabel('')\n","    plt.ylabel(predictor.replace('original_', ''), fontsize=15)\n","\n","    class_0_values = df_Original[df_Original[df_Original.columns[-1]] == 0][predictor]\n","    class_1_values = df_Original[df_Original[df_Original.columns[-1]] == 1][predictor]\n","    if len(set(class_0_values)) > 1 and len(set(class_1_values)) > 1:\n","        _, p_value = stats.ttest_ind(class_0_values, class_1_values, equal_var=False)  # Independent t-test\n","    else:\n","        _, p_value = stats.ranksums(class_0_values, class_1_values)  # Wilcoxon rank-sum test\n","\n","    # Check if p-value is less than 0.001 and display the appropriate text\n","    if p_value < 0.001:\n","        plt.text(0.5, 0.9, 'p < 0.001', transform=plt.gca().transAxes, ha='center', fontsize=12)\n","    else:\n","        plt.text(0.5, 0.9, f'p = {p_value:.4f}', transform=plt.gca().transAxes, ha='center', fontsize=12)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"executionInfo":{"elapsed":935,"status":"ok","timestamp":1697766703555,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"l89SWyBN_Wna","outputId":"21ec5aac-d83b-4596-cfe3-751ea528fc7f"},"outputs":[],"source":["import matplotlib.colors as mcolors\n","\n","cm = confusion_matrix(y_test.iloc[:, 0], (model_optimal.predict(X_test)[:, 0]> 0.5).astype(int))\n","class_labels = ['Not HG nor PDAC', 'HG or PDAC']\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False, xticklabels=class_labels, yticklabels=class_labels, annot_kws={\"size\": 25, \"weight\": \"bold\"})\n","ax = plt.gca()\n","ax.set_xticklabels(class_labels, fontsize=16, weight='bold')\n","ax.set_yticklabels(class_labels, fontsize=16, weight='bold')\n","plt.xlabel(\"Predicted\", fontsize=16)\n","plt.ylabel(\"Actual\", fontsize=16)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":669,"status":"ok","timestamp":1697766706631,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"9wBwhNwT_ycB","outputId":"70835e19-22c5-47d5-a2b4-4e1dcd504189"},"outputs":[],"source":["fpr, tpr, thresholds = roc_curve(y_test.iloc[:, 0], (model_optimal.predict(X_test)[:, 0]> 0.5).astype(int))\n","\n","# Plot ROC curve\n","plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(auc_score_optimal))\n","plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line (random classifier)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic Curve')\n","plt.legend(loc='lower right')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"32hSlNDwANSK"},"source":["# Invariant 75 Features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2545,"status":"ok","timestamp":1697766757551,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"sG7RhWUuAMT-","outputId":"b235338f-2a0b-4e48-9447-3dd1da0641ea"},"outputs":[],"source":["df_Empirical_Invariant = pd.read_excel(\"Empirical_Invariant_Feature_BraTS2020_Addclass.xlsx\", sheet_name=0)\n","df_Empirical_Invariant = df_Empirical_Invariant.drop('RecordName', axis=1)\n","print(df_Empirical_Invariant.shape)\n","print(df_Empirical_Invariant.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1697766760984,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"TQKaA-A2AegH","outputId":"4b8e89cf-0a8d-477a-8a2c-faa6f7249315"},"outputs":[],"source":["nan_rows, nan_columns = np.where(pd.isnull(df_Empirical_Invariant))\n","df_Empirical_Invariant = df_Empirical_Invariant.drop(df_Empirical_Invariant.index[nan_rows])\n","print(df_Empirical_Invariant.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":124,"status":"ok","timestamp":1697766804843,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"Lh8XKUXVySHw","outputId":"21df2262-d8a8-4e47-d597-1cfcebccb43d"},"outputs":[],"source":["# Original dataset. Malignant high-grade glioma (HGG)\n","# ['LGG - Malignant low-grade glioma', 0]\n","# ['HGG - Malignant high-grade glioma', 1]\n","mapping = {'HGG': 1, 'LGG': 0}\n","df_Empirical_Invariant['n_class'] = df_Empirical_Invariant['n_class'].replace(mapping)\n","X_Empirical_Invariant = df_Empirical_Invariant.iloc[:, :-1]\n","y_Empirical_Invariant = df_Empirical_Invariant.iloc[:, -1:]\n","print(type(y))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":121,"status":"ok","timestamp":1697766839596,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"Sgzxb28ZyaSi","outputId":"17549dd5-d414-44bd-f004-b8ddd78ed1a0"},"outputs":[],"source":["# Apply SMOTE to balance the dataset\n","from imblearn.over_sampling import SMOTE\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","\n","X_Empirical_resampled, y_Empirical_resampled = smote.fit_resample(X_Empirical_Invariant, y_Empirical_Invariant)\n","X_Empirical_resampled.shape, y_Empirical_resampled.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123,"status":"ok","timestamp":1697766855473,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"NEY6jBa6Al3b","outputId":"3d61d1f1-947e-4d2c-be83-6d6ac4dc6337"},"outputs":[],"source":["X_train_Empirical_Invariant, X_test_Empirical_Invariant, y_train_Empirical_Invariant, y_test_Empirical_Invariant = train_test_split(X_Empirical_resampled, \\\n","                                                                                                                                    y_Empirical_resampled, \\\n","                                                                                                                                    test_size=0.2, random_state=42)\n","print(X_train_Empirical_Invariant.shape)\n","print(y_train_Empirical_Invariant.shape)\n","print(X_test_Empirical_Invariant.shape)\n","print(y_test_Empirical_Invariant.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1697766857237,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"bfa-f1H8Aq63","outputId":"6b9bc626-482e-4bf5-91c9-af13aef2d024"},"outputs":[],"source":["count1 = y_test_Empirical_Invariant.iloc[:, 0].value_counts()[0]\n","count2 = y_test_Empirical_Invariant.iloc[:, 0].value_counts()[1]\n","print(count1)\n","print(count2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"agECpWntA1Uu"},"outputs":[],"source":["\"\"\"\n","  ada-boosting - stratified sampling\n","\"\"\"\n","\n","max_depth_range = np.arange(1, 20)\n","\n","train_accuracies_ada_EmpiricalInvariant = []\n","test_accuracies_ada_EmpiricalInvariant = []\n","train_losses_ada_EmpiricalInvariant = []\n","test_losses_ada_EmpiricalInvariant = []\n","\n","n_folds = 5\n","kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n","\n","for max_depth in max_depth_range:\n","    train_accuracy = []\n","    test_accuracy = []\n","    train_loss = []\n","    test_loss = []\n","    for train_index, val_index in kf.split(X_train_Empirical_Invariant):\n","        X_train1_Empirical_Invariant, X_val_Empirical_Invariant = X_train_Empirical_Invariant.iloc[train_index], X_train_Empirical_Invariant.iloc[val_index]\n","        y_train1_Empirical_Invariant, y_val1_Empirical_Invariant = y_train_Empirical_Invariant.iloc[train_index], y_train_Empirical_Invariant.iloc[val_index]\n","\n","        estimator = DecisionTreeRegressor(max_depth=max_depth, min_samples_split=10, criterion='squared_error', random_state=42)\n","        ada_boost = AdaBoostRegressor(estimator=estimator, n_estimators=200, learning_rate=0.002, loss='square', random_state=42)\n","        model_EmpiricalInvariant = MultiOutputRegressor(ada_boost)\n","        model_EmpiricalInvariant.fit(X_train1_Empirical_Invariant, y_train1_Empirical_Invariant)\n","\n","        train_accuracy.append(accuracy_score(y_train1_Empirical_Invariant.iloc[:, 0], (model_EmpiricalInvariant.predict(X_train1_Empirical_Invariant)[:, 0] > 0.5).astype(int)))\n","        test_accuracy.append(accuracy_score(y_test_Empirical_Invariant.iloc[:, 0], (model_EmpiricalInvariant.predict(X_test_Empirical_Invariant)[:, 0] > 0.5).astype(int)))\n","        train_loss.append(mean_absolute_error(y_train1_Empirical_Invariant, model_EmpiricalInvariant.predict(X_train1_Empirical_Invariant)))\n","        test_loss.append(mean_absolute_error(y_test_Empirical_Invariant, model_EmpiricalInvariant.predict(X_test_Empirical_Invariant)))\n","\n","    train_accuracies_ada_EmpiricalInvariant.append(np.mean(train_accuracy))\n","    test_accuracies_ada_EmpiricalInvariant.append(np.mean(test_accuracy))\n","    train_losses_ada_EmpiricalInvariant.append(np.mean(train_loss))\n","    test_losses_ada_EmpiricalInvariant.append(np.mean(test_loss))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":971},"executionInfo":{"elapsed":721,"status":"ok","timestamp":1697767431491,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"-EZVJJZEltvk","outputId":"7ae07913-a92f-4fd6-a068-ff635ab87f44"},"outputs":[],"source":["plt.plot(max_depth_range, train_accuracies_ada_EmpiricalInvariant, label='training')\n","plt.plot(max_depth_range, test_accuracies_ada_EmpiricalInvariant, label='testing')\n","\n","plt.xticks(np.arange(min(max_depth_range), max(max_depth_range)+1, 1, dtype=int))\n","\n","plt.xlabel('Depth', fontsize=20, fontweight='bold')\n","plt.ylabel('Accuracy', fontsize=20, fontweight='bold')\n","plt.legend()\n","plt.title('AdaBoost-Empirical-Invariant', fontsize=20, fontweight='bold')\n","plt.show()\n","\n","plt.plot(max_depth_range, train_losses_ada_EmpiricalInvariant, label='training')\n","plt.plot(max_depth_range, test_losses_ada_EmpiricalInvariant, label='testing')\n","\n","plt.xticks(np.arange(min(max_depth_range), max(max_depth_range)+1, 1, dtype=int))\n","\n","plt.xlabel('Depth', fontsize=20, fontweight='bold')\n","plt.ylabel('Loss', fontsize=20, fontweight='bold')\n","plt.legend()\n","plt.title('AdaBoost-Empirical-Invariant', fontsize=20, fontweight='bold')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMP7XygvE4eK"},"outputs":[],"source":["optimal_depth = 11\n","\n","train_accuracy_optimal = []\n","test_accuracy_optimal = []\n","train_loss_optimal = []\n","test_loss_optimal = []\n","\n","for train_index, val_index in kf.split(X_train_Empirical_Invariant):\n","  X_train1_EmpiricalInvariant_optimal, X_val1_EmpiricalInvariant_optimal = X_train_Empirical_Invariant.iloc[train_index], X_train_Empirical_Invariant.iloc[val_index]\n","  y_train1_EmpiricalInvariant_optimal, y_val1_EmpiricalInvariant_optimal = y_train_Empirical_Invariant.iloc[train_index], y_train_Empirical_Invariant.iloc[val_index]\n","\n","  estimator = DecisionTreeRegressor(max_depth=optimal_depth, min_samples_split=10, criterion='squared_error', random_state=42)\n","  ada_boost = AdaBoostRegressor(estimator=estimator, n_estimators=200, learning_rate=0.002, loss='square', random_state=42)\n","  model_EmpiricalInvariant_optimal = MultiOutputRegressor(ada_boost)\n","  model_EmpiricalInvariant_optimal.fit(X_train1_EmpiricalInvariant_optimal, y_train1_EmpiricalInvariant_optimal)\n","\n","  train_predictions_optimal_Empirical = (model_EmpiricalInvariant_optimal.predict(X_train1_EmpiricalInvariant_optimal)[:, 0] > 0.5).astype(int)\n","  test_predictions_optimal_Empirical = (model_EmpiricalInvariant_optimal.predict(X_test_Empirical_Invariant)[:, 0] > 0.5).astype(int)\n","\n","  train_accuracy_optimal.append(accuracy_score(y_train1_EmpiricalInvariant_optimal.iloc[:, 0], (model_EmpiricalInvariant_optimal.predict(X_train1_EmpiricalInvariant_optimal)[:, 0] > 0.5).astype(int)))\n","  test_accuracy_optimal.append(accuracy_score(y_test_Empirical_Invariant.iloc[:, 0], (model_EmpiricalInvariant_optimal.predict(X_test_Empirical_Invariant)[:, 0] > 0.5).astype(int)))\n","  train_loss_optimal.append(mean_absolute_error(y_train1_EmpiricalInvariant_optimal, model_EmpiricalInvariant_optimal.predict(X_train1_EmpiricalInvariant_optimal)))\n","  test_loss_optimal.append(mean_absolute_error(y_test_Empirical_Invariant, model_EmpiricalInvariant_optimal.predict(X_test_Empirical_Invariant)))\n","\n","train_accuracy_final = np.mean(train_accuracy_optimal)\n","test_accuracy_final = np.mean(test_accuracy_optimal)\n","train_loss_final = np.mean(train_loss)\n","test_loss_final = np.mean(test_loss)\n","\n","# Compute sensitivity and specificity\n","tn, fp, fn, tp = confusion_matrix(y_test_Empirical_Invariant.iloc[:, 0], (model_EmpiricalInvariant_optimal.predict(X_test_Empirical_Invariant)[:, 0] > 0.5).astype(int)).ravel()\n","sensitivity_EmpiricalInvariant_optimal = tp / (tp + fn)\n","specificity_EmpiricalInvariant_optimal = tn / (tn + fp)\n","\n","# Compute AUC score\n","auc_score_EmpiricalInvariant_optimal = roc_auc_score(y_test_Empirical_Invariant.iloc[:, 0], model_EmpiricalInvariant_optimal.predict(X_test_Empirical_Invariant)[:, 0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":203,"status":"ok","timestamp":1697768019751,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"pyfJiAlxcU5o","outputId":"81df89f7-8a29-4515-a64b-2a4bc72443f0"},"outputs":[],"source":["# Predictor Gain Calculation\n","feature_importances = np.zeros(X_train1_EmpiricalInvariant_optimal.shape[1])\n","\n","# Iterate over all the decision trees in the AdaBoost ensemble\n","for tree in model_EmpiricalInvariant_optimal.estimators_:\n","    decision_tree_model = tree.estimator\n","    decision_tree_model.fit(X_train1_EmpiricalInvariant_optimal, y_train1_EmpiricalInvariant_optimal)\n","    tree_importances = decision_tree_model.feature_importances_\n","    feature_importances += tree_importances\n","\n","# Normalize the importances to sum up to 100%\n","importance_percentage = (feature_importances / feature_importances.sum()) * 100\n","\n","# Modify the predictor names to remove \"original_\" part\n","predictor_names = [col.replace('original_', '') for col in df_Empirical_Invariant.columns[:-1]]\n","\n","# Create a DataFrame to store the feature importances and their names\n","importance_df = pd.DataFrame({\n","    'Predictor': predictor_names,\n","    'Importance (%)': importance_percentage\n","})\n","\n","# Sort the DataFrame based on importance in descending order\n","importance_df = importance_df.sort_values(by='Importance (%)', ascending=False)\n","\n","# Reset the index of the DataFrame for a cleaner representation\n","importance_df.reset_index(drop=True, inplace=True)\n","\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","\n","print(importance_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1712,"status":"ok","timestamp":1697768028454,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"WypLqspwcsvO","outputId":"b8c414c5-82e0-4ab2-8bac-15344aab73bc"},"outputs":[],"source":["# Plot the feature importances as a horizontal bar plot\n","colors = ['red' if i < 6 else 'blue' for i in range(importance_df.shape[0])]\n","\n","plt.figure(figsize=(8, 13))\n","plt.barh(importance_df['Predictor'], importance_df['Importance (%)'],  color=colors)\n","plt.xlabel('Gain', fontsize=20, fontweight='bold')\n","plt.ylabel('Radiomics Metric', fontsize=20, fontweight='bold')\n","#plt.title('Feature Importances')\n","\n","# Calculate cumulative gains\n","cumulative_gains = importance_df['Importance (%)'][::-1].cumsum()\n","\n","# Find the indices where cumulative gains cross 66% and 95%\n","index_66 = (cumulative_gains >= 66).idxmax()\n","index_95 = (cumulative_gains >= 95).idxmax()\n","\n","# Add horizontal lines for 66% and 95% cumulative gains\n","#plt.axhline(y=importance_df['Importance (%)'][index_66], color='green', linestyle='--', linewidth=1, label='66% Cumulative Gain')\n","#plt.axhline(y=importance_df['Importance (%)'][index_95], color='purple', linestyle='--', linewidth=1, label='95% Cumulative Gain')\n","\n","# Add a legend to the plot\n","plt.legend(loc='lower right', fontsize=12)\n","\n","plt.gca().invert_yaxis()  # Invert the y-axis to display the most important feature at the top\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2558,"status":"ok","timestamp":1697768444467,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"bcm_PAVNc8wN","outputId":"a95630b7-d0f6-4c3e-87e8-d47375a0ee11"},"outputs":[],"source":["from scipy import stats\n","\n","# Get the top six predictors\n","top_six_predictors = 'original_' + importance_df.iloc[:6]['Predictor']\n","\n","# Plot box plots for each of the top six predictors based on the target variable\n","plt.figure(figsize=(16, 10))\n","for i, predictor in enumerate(top_six_predictors):\n","    plt.subplot(2, 3, i + 1)\n","    sns.boxplot(x=df_Original[df_Original.columns[-1]].map({1: 'HGG', 0: 'LGG'}),\n","                y=df_Original[predictor], order=['HGG', 'LGG'])\n","    plt.xticks(fontsize=16)\n","    plt.xlabel('')\n","    plt.ylabel(predictor.replace('original_', ''), fontsize=16)\n","\n","    class_1_values = df_Original[df_Original[df_Original.columns[-1]] == 1][predictor]\n","    class_0_values = df_Original[df_Original[df_Original.columns[-1]] == 0][predictor]\n","    if len(set(class_0_values)) > 1 and len(set(class_1_values)) > 1:\n","        _, p_value = stats.ttest_ind(class_0_values, class_1_values, equal_var=False)  # Independent t-test\n","    else:\n","        _, p_value = stats.ranksums(class_0_values, class_1_values)  # Wilcoxon rank-sum test\n","\n","    # Check if p-value is less than 0.001 and display the appropriate text\n","    if p_value < 0.001:\n","        plt.text(0.5, 0.9, 'p < 0.001', transform=plt.gca().transAxes, ha='center', fontsize=14)\n","    else:\n","        plt.text(0.5, 0.9, f'p = {p_value:.4f}', transform=plt.gca().transAxes, ha='center', fontsize=14)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":131,"status":"ok","timestamp":1697768105855,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"wqYZCzGFF0Sb","outputId":"46762d59-b2c8-46b1-9b16-e57aa1db72ba"},"outputs":[],"source":["print(\"Sensitivity: {:.2f}\".format(sensitivity_EmpiricalInvariant_optimal))\n","print(\"Specificity: {:.2f}\".format(specificity_EmpiricalInvariant_optimal))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1697768132686,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"bM3SrNYGF5F4","outputId":"de3bc886-81fe-420b-dae2-90a3679ec0ab"},"outputs":[],"source":["cm = confusion_matrix(y_test_Empirical_Invariant.iloc[:, 0], (model_EmpiricalInvariant_optimal.predict(X_test_Empirical_Invariant)[:, 0] > 0.5).astype(int))\n","class_labels = ['LGD', 'HGD/PDAC']\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False, xticklabels=class_labels, yticklabels=class_labels, annot_kws={\"size\": 25, \"weight\": \"bold\"})\n","ax = plt.gca()\n","ax.set_xticklabels(class_labels, fontsize=16, weight='bold')\n","ax.set_yticklabels(class_labels, fontsize=16, weight='bold')\n","plt.xlabel(\"Predicted\", fontsize=16)\n","plt.ylabel(\"Actual\", fontsize=16)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":859,"status":"ok","timestamp":1697768135637,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"i7aAePOJGIBn","outputId":"8e1ba36f-ff76-454b-f399-4ef49e731b34"},"outputs":[],"source":["fpr, tpr, thresholds = roc_curve(y_test_Empirical_Invariant.iloc[:, 0], (model_EmpiricalInvariant_optimal.predict(X_test_Empirical_Invariant)[:, 0]> 0.5).astype(int))\n","\n","# Plot ROC curve\n","plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(auc_score_EmpiricalInvariant_optimal))\n","plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line (random classifier)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic Curve')\n","plt.legend(loc='lower right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3184,"status":"ok","timestamp":1697768319436,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"dq_urIGe31li","outputId":"ef4baa40-c834-4f74-a08f-12a0f99e99d9"},"outputs":[],"source":["# Number of bootstrap samples\n","n_bootstrap_samples = 1000\n","\n","sensitivity_values = []\n","specificity_values = []\n","auc_values = []\n","accuracy_values = []\n","\n","for _ in range(n_bootstrap_samples):\n","    # Resample the test dataset with replacement\n","    resampled_indices = np.random.choice(len(y_test_Empirical_Invariant), len(y_test_Empirical_Invariant), replace=True)\n","    y_test_Empirical_Invariant_resampled = y_test_Empirical_Invariant.iloc[resampled_indices]\n","    test_predictions_resampled = test_predictions_optimal_Empirical[resampled_indices]\n","\n","    # Calculate accuracy, sensitivity and specificity for the resampled dataset\n","    tn, fp, fn, tp = confusion_matrix(y_test_Empirical_Invariant_resampled.iloc[:, 0], test_predictions_resampled).ravel()\n","    sensitivity = tp / (tp + fn)\n","    specificity = tn / (tn + fp)\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","\n","    # Calculate AUC for the resampled dataset\n","    auc = roc_auc_score(y_test_Empirical_Invariant_resampled.iloc[:, 0], test_predictions_resampled)\n","\n","    # Store the sensitivity, specificity, and AUC values\n","    sensitivity_values.append(sensitivity)\n","    specificity_values.append(specificity)\n","    accuracy_values.append(accuracy)\n","    auc_values.append(auc)\n","\n","# Calculate 95% confidence intervals (percentiles) for accuracy, sensitivity, specificity, and AUC\n","sensitivity_ci = np.percentile(sensitivity_values, [2.5, 97.5])\n","specificity_ci = np.percentile(specificity_values, [2.5, 97.5])\n","accuracy_ci = np.percentile(accuracy_values, [2.5, 97.5])\n","auc_ci = np.percentile(auc_values, [2.5, 97.5])\n","\n","print(\"Accuracy 95% CI:\", accuracy_ci)\n","print(\"Sensitivity 95% CI:\", sensitivity_ci)\n","print(\"Specificity 95% CI:\", specificity_ci)\n","print(\"AUC 95% CI:\", auc_ci)"]},{"cell_type":"markdown","metadata":{"id":"_kM8zbAgIxjn"},"source":["# Comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":623,"status":"ok","timestamp":1697768148256,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":240},"id":"9CuNpzkWdMhz","outputId":"5d4d0c14-43d4-4e99-a503-012e7ec98bcf"},"outputs":[],"source":["max_accuracy_Original = max(test_accuracies_ada)\n","max_accuracy_EmpiricalInvariant = max(test_accuracies_ada_EmpiricalInvariant)\n","\n","headers = pd.MultiIndex.from_tuples([\n","    (\"Original Texture Features\", \"75 features\"),\n","    (\"Eimirical Invariant Features\", \"75 features\")\n","])\n","\n","df = pd.DataFrame({\n","    headers[0]: [sensitivity_optimal, specificity_optimal, auc_score_optimal, max_accuracy_Original],\n","    headers[1]: [sensitivity_EmpiricalInvariant_optimal, specificity_EmpiricalInvariant_optimal, auc_score_EmpiricalInvariant_optimal, max_accuracy_EmpiricalInvariant]\n","}, index=[\"Sensitivity\", \"Specificity\", \"AUC\", \"Accuracy\"])\n","\n","styled_df = df.style.format(\"{:.2f}\")\n","\n","styles = [\n","    {'selector': 'td',\n","     'props': [('border-right', 'solid 1px')]\n","    }\n","]\n","\n","styled_df.set_table_styles(styles)\n","styled_df"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM5IFdw7HAuGSvdp9QupJjZ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
