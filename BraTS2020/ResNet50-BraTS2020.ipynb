{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8285,"status":"ok","timestamp":1701996118875,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"AimQrGKjCs3y"},"outputs":[],"source":["from IPython.display import clear_output\n","!pip install imutils\n","clear_output()\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25287,"status":"ok","timestamp":1701996147641,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"tphG8ndggEfE","outputId":"cf2b15e4-897d-443b-a740-7491c4ad741d"},"outputs":[],"source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","path = \"/BraTS20-Invariant-feature/BraTS2020_ResNet50_Split/\"\n","os.chdir(path)\n","os.getcwd()\n","IMG_PATH = \"/BraTS20-Invariant-feature/BraTS2020_ResNet50/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":1067,"status":"ok","timestamp":1701996229373,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"SpfOBuB-Aw_W","outputId":"b846996e-9810-48a0-eff4-b2e89c25a585"},"outputs":[],"source":["import numpy as np\n","from tqdm import tqdm\n","import cv2\n","import os\n","import shutil\n","import itertools\n","import imutils\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","import plotly.graph_objs as go\n","from plotly.offline import init_notebook_mode, iplot\n","from plotly import tools\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras import layers\n","from keras.models import Model, Sequential\n","from keras.optimizers import Adam, RMSprop\n","from keras.callbacks import EarlyStopping\n","\n","init_notebook_mode(connected=True)\n","RANDOM_SEED = 123"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1862,"status":"ok","timestamp":1701957668768,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"PQy75JaHfqYB","outputId":"92331566-d975-463a-ffae-64bc8227b2da"},"outputs":[],"source":["!apt-get install tree\n","!mkdir TRAIN VAL TEST TRAIN/HGG TRAIN/LGG VAL/HGG VAL/LGG TEST/HGG TEST/LGG\n","!tree -d"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19Jv5k4XQUXA"},"outputs":[],"source":["# split the data by train/val/test\n","for CLASS in os.listdir(IMG_PATH):\n","    if not CLASS.startswith('.'):\n","        IMG_NUM = len(os.listdir(IMG_PATH + CLASS))\n","        for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH + CLASS)):\n","            img = IMG_PATH + CLASS + '/' + FILE_NAME\n","            if not FILE_NAME.startswith('.'):\n","              if n < 5:\n","                  shutil.copy(img, path + 'TEST/' + CLASS.upper() + '/' + FILE_NAME)\n","              elif n < 0.8*IMG_NUM:\n","                  shutil.copy(img, path + 'TRAIN/'+ CLASS.upper() + '/' + FILE_NAME)\n","              else:\n","                  shutil.copy(img, path + 'VAL/'+ CLASS.upper() + '/' + FILE_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vlxAEn5OQz9J"},"outputs":[],"source":["def load_data(dir_path, img_size=(100,100)):\n","    \"\"\"\n","    Load resized images as np.arrays to workspace\n","    \"\"\"\n","    X = []\n","    y = []\n","    i = 0\n","    labels = dict()\n","    for path in tqdm(sorted(os.listdir(dir_path))):\n","        if not path.startswith('.'):\n","            labels[i] = path\n","            for file in os.listdir(dir_path + path):\n","                if not file.startswith('.'):\n","                    img = cv2.imread(dir_path + path + '/' + file)\n","                    X.append(img)\n","                    y.append(i)\n","            i += 1\n","    X = np.array(X)\n","    y = np.array(y)\n","    print(f'{len(X)} images loaded from {dir_path} directory.')\n","    return X, y, labels\n","\n","\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.figure(figsize = (6,6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    cm = np.round(cm,2)\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1385,"status":"ok","timestamp":1701957702352,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"uVQsfqKjQ4Hn","outputId":"31dbb083-8d20-4023-b134-25e249558650"},"outputs":[],"source":["TRAIN_DIR = 'TRAIN/'\n","TEST_DIR = 'TEST/'\n","VAL_DIR = 'VAL/'\n","IMG_SIZE = (224,224)\n","\n","# use predefined function to load the image data into workspace\n","X_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\n","X_test, y_test, _ = load_data(TEST_DIR, IMG_SIZE)\n","X_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":738},"executionInfo":{"elapsed":1273,"status":"ok","timestamp":1701957728450,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"B2QJaeAiRniG","outputId":"73fda03f-c6ab-488c-fdcd-2044c17a2e1e"},"outputs":[],"source":["def plot_samples(X, y, labels_dict, n=50):\n","    \"\"\"\n","    Creates a gridplot for desired number of images (n) from the specified set\n","    \"\"\"\n","    for index in range(len(labels_dict)):\n","        imgs = X[np.argwhere(y == index)][:n]\n","        j = 10\n","        i = int(n/j)\n","\n","        plt.figure(figsize=(15,6))\n","        c = 1\n","        for img in imgs:\n","            plt.subplot(i,j,c)\n","            plt.imshow(img[0])\n","\n","            plt.xticks([])\n","            plt.yticks([])\n","            c += 1\n","        plt.suptitle('Tumor: {}'.format(labels_dict[index]))\n","        plt.show()\n","\n","plot_samples(X_train, y_train, labels, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWr93uMWSB_z"},"outputs":[],"source":["def crop_imgs(set_name, add_pixels_value=0):\n","    \"\"\"\n","    Finds the extreme points on the image and crops the rectangular out of them\n","    \"\"\"\n","    set_new = []\n","    for img in set_name:\n","        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","        # threshold the image, then perform a series of erosions +\n","        # dilations to remove any small regions of noise\n","        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n","        thresh = cv2.erode(thresh, None, iterations=2)\n","        thresh = cv2.dilate(thresh, None, iterations=2)\n","\n","        # find contours in thresholded image, then grab the largest one\n","        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        cnts = imutils.grab_contours(cnts)\n","        c = max(cnts, key=cv2.contourArea)\n","\n","        # find the extreme points\n","        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n","        extRight = tuple(c[c[:, :, 0].argmax()][0])\n","        extTop = tuple(c[c[:, :, 1].argmin()][0])\n","        extBot = tuple(c[c[:, :, 1].argmax()][0])\n","\n","        ADD_PIXELS = add_pixels_value\n","        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n","        set_new.append(new_img)\n","\n","    return np.array(set_new)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxGL8vSBSIRO"},"outputs":[],"source":["img = cv2.imread('/BraTS20-Invariant-feature/BraTS2020_ResNet50/HGG/BraTS20_Training_001_t2.jpg')\n","img = cv2.resize(\n","            img,\n","            dsize=IMG_SIZE,\n","            interpolation=cv2.INTER_CUBIC\n","        )\n","gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","gray = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","# threshold the image, then perform a series of erosions +\n","# dilations to remove any small regions of noise\n","thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n","thresh = cv2.erode(thresh, None, iterations=2)\n","thresh = cv2.dilate(thresh, None, iterations=2)\n","\n","# find contours in thresholded image, then grab the largest one\n","cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","cnts = imutils.grab_contours(cnts)\n","c = max(cnts, key=cv2.contourArea)\n","\n","# find the extreme points\n","extLeft = tuple(c[c[:, :, 0].argmin()][0])\n","extRight = tuple(c[c[:, :, 0].argmax()][0])\n","extTop = tuple(c[c[:, :, 1].argmin()][0])\n","extBot = tuple(c[c[:, :, 1].argmax()][0])\n","\n","# add contour on the image\n","img_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n","\n","# add extreme points\n","img_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\n","img_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\n","img_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\n","img_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n","\n","# crop\n","ADD_PIXELS = 0\n","new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"elapsed":792,"status":"ok","timestamp":1701957741763,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"2GNUlbkvSYIn","outputId":"61475cfe-77eb-4379-97f8-47df6dedf705"},"outputs":[],"source":["plt.figure(figsize=(15,6))\n","plt.subplot(141)\n","plt.imshow(img)\n","plt.xticks([])\n","plt.yticks([])\n","plt.title('Step 1. Get the original image')\n","plt.subplot(142)\n","plt.imshow(img_cnt)\n","plt.xticks([])\n","plt.yticks([])\n","plt.title('Step 2. Find the biggest contour')\n","plt.subplot(143)\n","plt.imshow(img_pnt)\n","plt.xticks([])\n","plt.yticks([])\n","plt.title('Step 3. Find the extreme points')\n","plt.subplot(144)\n","plt.imshow(new_img)\n","plt.xticks([])\n","plt.yticks([])\n","plt.title('Step 4. Crop the image')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1701957747588,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"_h1YmP8meUwz","outputId":"e3aa84bc-9703-4a45-bbac-3e49c3f09aaa"},"outputs":[],"source":["# apply this for each set\n","X_train_crop = crop_imgs(set_name=X_train)\n","X_val_crop = crop_imgs(set_name=X_val)\n","X_test_crop = crop_imgs(set_name=X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":741},"executionInfo":{"elapsed":1431,"status":"ok","timestamp":1701957751291,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"N0OaYi97eZUm","outputId":"18d059a2-e802-4ebb-db0e-5024fd6316b4"},"outputs":[],"source":["plot_samples(X_train_crop, y_train, labels, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dN5mt6ZGmBDS"},"outputs":[],"source":["def save_new_images(x_set, y_set, folder_name):\n","    i = 0\n","    for (img, imclass) in zip(x_set, y_set):\n","        if imclass == 0:\n","            cv2.imwrite(folder_name+'LGG/'+str(i)+'.jpg', img)\n","        else:\n","            cv2.imwrite(folder_name+'HGG/'+str(i)+'.jpg', img)\n","        i += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1701980337259,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"f25kdIZVnZap","outputId":"94034041-be33-4e72-aa49-b916fe99c76f"},"outputs":[],"source":["path = \"/BraTS20-Invariant-feature/BraTS2020_ResNet50_Crop/\"\n","os.chdir(path)\n","os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2fwMQ8zl1h2"},"outputs":[],"source":["import os\n","import cv2\n","\n","def save_new_images(images, labels, folder_name):\n","    for i, (image, label) in enumerate(zip(images, labels)):\n","        label_folder = os.path.join(folder_name, 'HGG' if label == 1 else 'LGG')\n","        os.makedirs(label_folder, exist_ok=True)\n","\n","        image_filename = os.path.join(label_folder, f'image_{i}.png')\n","        cv2.imwrite(image_filename, image)\n","\n","# Create directories and save images\n","save_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP/')\n","save_new_images(X_val_crop, y_val, folder_name='VAL_CROP/')\n","save_new_images(X_test_crop, y_test, folder_name='TEST_CROP/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3316,"status":"ok","timestamp":1701963827952,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"Q9C0gTp4esGD","outputId":"c717988b-4eaa-4044-b1f5-5a5f0a893e75"},"outputs":[],"source":["import keras\n","from keras.layers import BatchNormalization\n","\n","NUM_CLASSES = 1\n","\n","# use the pre-trained ResNet50 model\n","resnet50_x = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","resnet50 = Sequential()\n","resnet50.add(resnet50_x)\n","resnet50.add(layers.Dropout(0.3))\n","resnet50.add(layers.Flatten())\n","resnet50.add(layers.Dropout(0.5))\n","resnet50.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n","#resnet50.add(BatchNormalization())\n","\n","resnet50.layers[0].trainable = False\n","\n","resnet50.compile(\n","    loss='binary_crossentropy',\n","    optimizer=RMSprop(learning_rate=1e-4),\n","    metrics=['accuracy']\n",")\n","\n","resnet50.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1701963833110,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"NqbgYMHZpKBn","outputId":"748afedb-ad6c-48bd-deb5-607c24525985"},"outputs":[],"source":["TRAIN_DIR = 'TRAIN_CROP/'\n","VAL_DIR = 'VAL_CROP/'\n","\n","# No data augmentation for training set\n","train_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input\n",")\n","\n","# No data augmentation for validation set\n","test_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","    TRAIN_DIR,\n","    color_mode='rgb',\n","    target_size=IMG_SIZE,\n","    batch_size=64,\n","    class_mode='binary',\n","    seed=RANDOM_SEED\n",")\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    VAL_DIR,\n","    color_mode='rgb',\n","    target_size=IMG_SIZE,\n","    batch_size=32,\n","    class_mode='binary',\n","    seed=RANDOM_SEED\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261727,"status":"ok","timestamp":1701964099054,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"3z_s2_T3lI83","outputId":"333c34fb-fe6b-4874-9b81-9feeb989300a"},"outputs":[],"source":["import time\n","\n","start = time.time()\n","\n","resnet50_history = resnet50.fit(\n","    train_generator,\n","    steps_per_epoch=5,\n","    epochs=150,\n","    validation_data=validation_generator,\n","    validation_steps=3,\n",")\n","\n","end = time.time()\n","print(end - start)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"elapsed":293,"status":"error","timestamp":1701980068339,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"MAIZCvd-90LU","outputId":"ad7b7c94-d318-4ec9-f2c6-345a8ed33c0c"},"outputs":[],"source":["import pandas as pd\n","\n","# Assuming resnet50_history is a History object returned by the fit method\n","resnet50_accuracy = resnet50_history.history['accuracy']\n","resnet50_loss = resnet50_history.history['loss']\n","resnet50_val_accuracy = resnet50_history.history['val_accuracy']\n","resnet50_val_loss = resnet50_history.history['val_loss']\n","\n","# Create a DataFrame\n","df = pd.DataFrame({\n","    'Accuracy': resnet50_accuracy,\n","    'Loss': resnet50_loss,\n","    'Validation Accuracy': resnet50_val_accuracy,\n","    'Validation Loss': resnet50_val_loss\n","})\n","\n","# Save to Excel file\n","df.to_excel('resnet50_history.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":1385,"status":"ok","timestamp":1701980344288,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"3NeTQ7O7EPD-","outputId":"fe91861f-f1c4-406b-c87f-9443a86845c5"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Read the Excel file\n","df = pd.read_excel('resnet50_history.xlsx')\n","\n","# Plot training and validation accuracy\n","plt.figure(figsize=(12, 6))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(df['Accuracy'], label='Training Accuracy')\n","plt.plot(df['Validation Accuracy'], label='Validation Accuracy')\n","plt.title('BraTS2020-ResNet50')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","# Plot training and validation loss\n","plt.subplot(1, 2, 2)\n","plt.plot(df['Loss'], label='Training Loss')\n","plt.plot(df['Validation Loss'], label='Validation Loss')\n","plt.title('BraTS2020-ResNet50')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1701967152193,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"DtIfh4K2HtVY","outputId":"dbc667e5-030f-4f1f-87ed-c2c9c0660b6b"},"outputs":[],"source":["y_pred = resnet50.predict(validation_generator)\n","y_pred_binary = np.round(y_pred)\n","y_true = validation_generator.classes\n","conf_mat = confusion_matrix(y_true, y_pred_binary)\n","print(\"Confusion Matrix:\")\n","print(conf_mat)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1701996301507,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"pFWjv6o1JSjY"},"outputs":[],"source":["#sensitivity = cm_ori[0,0]/(cm_ori[0,0]+cm_ori[0,1])\n","#specificity = cm_ori[1,1]/(cm_ori[1,0]+cm_ori[1,1])\n","\n","conf_mat_shape = (2, 2)\n","desired_values = [11, 4, 8, 33]\n","conf_mat1 = np.reshape(desired_values, conf_mat_shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1701996302864,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"1jtL1lnZLfGC","outputId":"6fb6839c-d829-4cf9-c9a1-e4916655cff2"},"outputs":[],"source":["sensitivity = conf_mat1[0,0]/(conf_mat1[0,0]+conf_mat1[0,1])\n","print('Sensitivity : ', sensitivity )\n","\n","specificity = conf_mat1[1,1]/(conf_mat1[1,0]+conf_mat1[1,1])\n","print('Specificity : ', specificity)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1701996309766,"user":{"displayName":"Yukun Yan","userId":"07285956172058504749"},"user_tz":300},"id":"Z2RLER4DEvFh","outputId":"b46e2da5-6dc5-4f76-ac32-dfc6d46533e1"},"outputs":[],"source":["import matplotlib.colors as mcolors\n","import seaborn as sns\n","class_labels = ['LGG', 'HGG']\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_mat1, annot=True, cmap='Blues', fmt='d', cbar=False, xticklabels=class_labels, yticklabels=class_labels, annot_kws={\"size\": 25, \"weight\": \"bold\"})\n","ax = plt.gca()\n","ax.set_xticklabels(class_labels, fontsize=16, weight='bold')\n","ax.set_yticklabels(class_labels, fontsize=16, weight='bold')\n","plt.xlabel(\"Predicted\", fontsize=14, weight='bold')\n","plt.ylabel(\"Actual\", fontsize=14, weight='bold')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNEdScH1HkBv45qtYxxYJXj","gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
